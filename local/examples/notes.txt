https://daign.github.io/clipping-with-caps/

2 options

1 => try to push the cameras into the scene
2 => figure out the transform on the scene, render clipping

could I position, render, clip?

Yes, 


      <      O

Render dist clipping min is start of sphere. 

position the model based on the moment bubble
set the clip distance at the edge of the bubble
render the scene using the same renderer 
-> no, render using another renderer to another canvas then clip the circle and use that for texture. 
-> but the resolution issue... 

ok, maybe I can just clip things

https://github.com/mrdoob/three.js/blob/master/examples/webgl_clipping_advanced.html

I would just have a make a 16 or 32 sided clip cone. hmmm.... but what about other geometry in the scene?

render overlaying might be better...

greenscreen?

Material might be better...

loader.addEventListener( 'load', function ( event ) {
    var object = event.content;
    object.traverse( function ( child ) {
        if ( child instanceof THREE.Mesh ) {
            child.material = material;
        }
    } );
    scene.add( object );
});


draw only the bubble circle to the canvas


Problem: 
When looking at a moment, the background gets overwritten by the moment scene, with the depth of the moment

So we redner that scene separately with the XR camera

Then we draw it to a object in the scene with the right clipping. 


OK, so, set scissor limits the render: 
https://threejs.org/docs/#api/en/renderers/WebGLRenderer.setScissor

so maybe what I could do it add a plane, have the plane resize to match the render view...? no, that wouldn't work... 
durp durp

ok, not good, but might work

render scene offscren, read pixels and write to material. I would have to scale wouldn't I?

I really just want a proper pipeline for this. 
The thing is that these pixels need to be read at the right layer, and a material is the way to do that. The thing is that the pixel values should be read 
from somewhere else. 

ok, we'll use the bad multiscaly version. 

So, we read it won't be angled. 

there will be a flat plane that we write to. we get the corners of the plane in pixels, and transfer that to our material. 

https://threejs.org/docs/#api/en/renderers/WebGLRenderTarget


Right, texture has to be different for the left and right eyes. Gah. 

ok, so texture is out, I need either a render jobby or... 
No, it's gotta be a render pipline. 

back to the clipping idea? I'm have to reverce clip the world. WHile possible, it just oudsn like a bad idea. 

so what I want is that when we render a pixel for a particular object, we instead go to another scene to get them. 

oh, layers

have two planes, one pointed at one eye, the other pointed at the other eye. put them on the different layers
https://discourse.threejs.org/t/layers-and-webxr/17751
https://threejs.org/docs/#api/en/renderers/webxr/WebXRManager.getCamera

ok, new plan. 
back to single renderers and textures (I think)

place and scale scene
get cameras
for each camera
position plane orthogonally
render using camera
draw relevant section to canvas? 

